{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import __init__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Consolidation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will try to consolidate the 3 models we have in a better one by studying their score on different type of data, and their correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GT 730M (CNMeM is disabled, CuDNN not available)\n",
      "/usr/local/lib/python2.7/dist-packages/theano/tensor/signal/downsample.py:5: UserWarning: downsample module has been moved to the pool module.\n",
      "  warnings.warn(\"downsample module has been moved to the pool module.\")\n"
     ]
    }
   ],
   "source": [
    "from framework import models\n",
    "\n",
    "from framework.datatools import Data, greyplot\n",
    "\n",
    "from framework.config import LOCS\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from framework.utils import split_data_new, preprocess3, sampling_augmentation, preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data for Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m3 = models.get('model3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X3, y3 = m3.data.load_train_data('model3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unshuffling..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_sorted = np.load(LOCS.y_train_patt.format('model3'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_sys_dia = []\n",
    "fi = csv.reader(open(LOCS.train_csv))\n",
    "for line in fi:\n",
    "    idx = line[0]\n",
    "    systole = line[1]\n",
    "    diastole = line[2]\n",
    "    id_sys_dia.append((idx,systole,diastole))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_to_id = []\n",
    "cursor = 0\n",
    "for x in id_sys_dia[1:]:\n",
    "    if y_sorted[cursor]!=float(x[1]): continue\n",
    "    y_to_id.append((x[0],'systole'))\n",
    "    cursor += 1\n",
    "    if y_sorted[cursor]!=float(x[2]): print 'oh oh...'\n",
    "    y_to_id.append((x[0],'diastole'))\n",
    "    cursor += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(12345)\n",
    "np.random.shuffle(y_to_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X3_train, y3_train, X3_test, y3_test = split_data_new(X3,y3,split_ratio = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "split = int(X3.shape[0] * 0.2)\n",
    "id_test = y_to_id[:split]\n",
    "id_train = y_to_id[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting with Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing images...\n",
      "\r",
      "  1/198 [..............................] - ETA: 21s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/skimage/util/dtype.py:111: UserWarning: Possible precision loss when converting from float32 to uint16\n",
      "  \"%s to %s\" % (dtypeobj_in, dtypeobj))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198/198 [==============================] - 22s    \n"
     ]
    }
   ],
   "source": [
    "print('Pre-processing images...')\n",
    "X3_pre = preprocess3(X3_test,weight=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model3 = m3.model.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model3.load_weights('./framework/models/model3/implementations/impl2 (saved)/weights_best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting on validation data and boosting...\n",
      "0 / 20\n",
      "198/198 [==============================] - 0s     \n",
      "198/198 [==============================] - 2s     \n",
      "1 / 20\n",
      "198/198 [==============================] - 0s     \n",
      "198/198 [==============================] - 1s     \n",
      "2 / 20\n",
      "198/198 [==============================] - 0s     \n",
      "198/198 [==============================] - 1s     \n",
      "3 / 20\n",
      "198/198 [==============================] - 0s     \n",
      "198/198 [==============================] - 1s     \n",
      "4 / 20\n",
      "198/198 [==============================] - 0s     \n",
      "198/198 [==============================] - 1s     \n",
      "5 / 20\n",
      "198/198 [==============================] - 0s     \n",
      "198/198 [==============================] - 1s     \n",
      "6 / 20\n",
      "198/198 [==============================] - 0s     \n",
      "198/198 [==============================] - 1s     \n",
      "7 / 20\n",
      "198/198 [==============================] - 0s     \n",
      "198/198 [==============================] - 1s     \n",
      "8 / 20\n",
      "198/198 [==============================] - 0s     \n",
      "198/198 [==============================] - 1s     \n",
      "9 / 20\n",
      "198/198 [==============================] - 0s     \n",
      "198/198 [==============================] - 1s     \n",
      "10 / 20\n",
      "198/198 [==============================] - 0s     \n",
      "198/198 [==============================] - 1s     \n",
      "11 / 20\n",
      "198/198 [==============================] - 0s     \n",
      "198/198 [==============================] - 1s     \n",
      "12 / 20\n",
      "198/198 [==============================] - 0s     \n",
      "198/198 [==============================] - 1s     \n",
      "13 / 20\n",
      "198/198 [==============================] - 0s     \n",
      "198/198 [==============================] - 1s     \n",
      "14 / 20\n",
      "198/198 [==============================] - 0s     \n",
      "198/198 [==============================] - 1s     \n",
      "15 / 20\n",
      "198/198 [==============================] - 0s     \n",
      "198/198 [==============================] - 1s     \n",
      "16 / 20\n",
      "198/198 [==============================] - 0s     \n",
      "198/198 [==============================] - 1s     \n",
      "17 / 20\n",
      "198/198 [==============================] - 0s     \n",
      "198/198 [==============================] - 1s     \n",
      "18 / 20\n",
      "198/198 [==============================] - 0s     \n",
      "198/198 [==============================] - 1s     \n",
      "19 / 20\n",
      "198/198 [==============================] - 0s     \n",
      "198/198 [==============================] - 1s     \n"
     ]
    }
   ],
   "source": [
    "N_boost = 20\n",
    "batch_size = 64\n",
    "\n",
    "preds = []\n",
    "\n",
    "print('Predicting on validation data and boosting...')\n",
    "\n",
    "for i in range(N_boost):\n",
    "    print i,'/',N_boost\n",
    "    X3_sampled = sampling_augmentation(X3_pre,5)\n",
    "    pred_temp = model3.predict(X3_sampled,batch_size = batch_size, verbose=1)\n",
    "    preds.append(pred_temp)\n",
    "    \n",
    "pred = np.mean(preds,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = np.array([x[0] for x in pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def sq(x):\n",
    "    return x*x\n",
    "sq = np.vectorize(sq)\n",
    "\n",
    "def rmse(pred,vals):\n",
    "    diff = pred - vals\n",
    "    return math.sqrt(np.mean(sq(diff)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.324511811556523"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(pred,y3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_systole = np.array([p for i,p in enumerate(pred) if id_test[i][1] == 'systole'])\n",
    "pred_diastole = np.array([p for i,p in enumerate(pred) if id_test[i][1] == 'diastole'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y3_test_systole = np.array([p for i,p in enumerate(y3_test) if id_test[i][1] == 'systole'])\n",
    "y3_test_diastole = np.array([p for i,p in enumerate(y3_test) if id_test[i][1] == 'diastole'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.8874601231\n",
      "37.1317683511\n"
     ]
    }
   ],
   "source": [
    "print rmse(pred_systole,y3_test_systole)\n",
    "print rmse(pred_diastole,y3_test_diastole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accumulate_study_results(ids, prob):\n",
    "    \"\"\"\n",
    "    Accumulate results per study (because one study has many SAX slices),\n",
    "    so the averaged CDF for all slices is returned.\n",
    "    \"\"\"\n",
    "    sum_result = {}\n",
    "    cnt_result = {}\n",
    "    size = prob.shape[0]\n",
    "    for i in range(size):\n",
    "        study_id = ids[i]\n",
    "        idx = int(study_id)\n",
    "        if idx not in cnt_result:\n",
    "            cnt_result[idx] = 0.\n",
    "            sum_result[idx] = np.zeros((1, prob.shape[1]), dtype=np.float32)\n",
    "        cnt_result[idx] += 1\n",
    "        sum_result[idx] += prob[i, :]\n",
    "    for i in cnt_result.keys():\n",
    "        sum_result[i][:] /= cnt_result[i]\n",
    "    return sum_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data for Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m4 = models.get('model4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X4, y4 = m4.data.load_train_data('model4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X4_train, y4_train, X4_test, y4_test = m4.train.split_data(X4,y4,split_ratio = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting with model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model4_systole = m4.model.get_model()\n",
    "model4_diastole = m4.model.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model4_systole.load_weights('./framework/models/model4/implementations/impl1/weights_systole_best.hdf5')\n",
    "model4_diastole.load_weights('./framework/models/model4/implementations/impl1/weights_diastole_best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1066/1066 [==============================] - 101s   \n"
     ]
    }
   ],
   "source": [
    "X4_pre = preprocess(X4_test,weight=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1066/1066 [==============================] - 24s    \n",
      "1066/1066 [==============================] - 13s    \n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "pred_systole = model4_systole.predict(X4_pre,batch_size = batch_size,verbose=1)\n",
    "pred_diastole = model4_diastole.predict(X4_pre,batch_size = batch_size,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_systole = np.array([x[0] for x in pred_systole])\n",
    "pred_diastole = np.array([x[0] for x in pred_diastole])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y4_test_systole = np.array([x[0] for x in y4_test])\n",
    "y4_test_diastole = np.array([x[1] for x in y4_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.6690100776\n",
      "40.39286627\n"
     ]
    }
   ],
   "source": [
    "print rmse(pred_systole,y4_test_systole)\n",
    "print rmse(pred_diastole,y4_test_diastole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data for Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from model1.model import get_model\n",
    "from model1.data import load_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from model1.train import split_data as sd1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1, y1 = load_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1_train, y1_train, X1_test, y1_test = sd1(X1, y1, split_ratio = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting with Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1_systole = get_model()\n",
    "model1_diastole = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1_systole.load_weights('./model1/weights_systole_best.hdf5')\n",
    "model1_diastole.load_weights('./model1/weights_diastole_best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1066/1066 [==============================] - 124s   \n"
     ]
    }
   ],
   "source": [
    "X1_pre = preprocess(X1_test, weight=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1066/1066 [==============================] - 14s    \n",
      "1066/1066 [==============================] - 15s    \n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "pred1_systole = model1_systole.predict(X1_pre,batch_size = batch_size,verbose=1)\n",
    "pred1_diastole = model1_diastole.predict(X1_pre,batch_size = batch_size,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred1_systole = np.array([x[0] for x in pred1_systole])\n",
    "pred1_diastole = np.array([x[0] for x in pred1_diastole])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y1_test_systole = np.array([x[0] for x in y1_test])\n",
    "y1_test_diastole = np.array([x[1] for x in y1_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.7758541493\n",
      "33.8968973338\n"
     ]
    }
   ],
   "source": [
    "print rmse(pred1_systole,y1_test_systole)\n",
    "print rmse(pred1_diastole,y1_test_diastole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
